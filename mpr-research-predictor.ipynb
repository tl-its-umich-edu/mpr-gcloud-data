{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89fc6bd-7957-491e-8ff9-43ddb7e4516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\n",
      "Installing collected packages: tokenizers, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.8.1 regex-2022.6.2 tokenizers-0.12.1 transformers-4.20.1\n",
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m759.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.2.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.0\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (5.2.1.post0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in ./.local/lib/python3.7/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in ./.local/lib/python3.7/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (6.13.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets) (7.33.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (21.3)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.3.1)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.29)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (2.12.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets) (59.8.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.11)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (23.0.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.4.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->ipykernel>=4.5.1->ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.15.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.7/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.4)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.8.0)\n",
      "Installing collected packages: ipywidgets\n",
      "Successfully installed ipywidgets-7.7.1\n",
      "Requirement already satisfied: torchserve in ./.local/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: future in ./.local/lib/python3.7/site-packages (from torchserve) (0.18.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchserve) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from torchserve) (5.9.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from torchserve) (0.37.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from torchserve) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torchserve) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers --upgrade\n",
    "!pip install torch --upgrade\n",
    "!pip install ipywidgets --upgrade\n",
    "!pip install torchserve --upgrade\n",
    "\n",
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632f5f7d-9ce9-4648-90cb-3c7013a1bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import google.auth\n",
    "from google.cloud import storage, bigquery\n",
    "from google.cloud import exceptions as GCPExceptions\n",
    "\n",
    "from transformers import (RobertaConfig, RobertaTokenizer,\n",
    "                          RobertaForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "#import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-4s [%(filename)s:%(lineno)d] - %(message)s',\n",
    "    datefmt='%Y-%m-%dT%H:%M:%S%z',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "class trainerConfig:\n",
    "    def __init__(self):\n",
    "        self.tierLevel: int = 1\n",
    "        self.vocabularySize: int = 50265\n",
    "        self.hiddenLayers: int = -1\n",
    "        self.batchSize: int = 16\n",
    "        \n",
    "        self.robertaModel = None\n",
    "        self.modelName = None\n",
    "        \n",
    "    \n",
    "    def setUpFromArgs(self):\n",
    "        parserNamespace = setUpParser()\n",
    "        self.vocabularySize = parserNamespace.vocabulary_size\n",
    "        self.hiddenLayers = parserNamespace.hidden_layers\n",
    "        # self.tierLevel = parserNamespace.tier_level\n",
    "        self.batchSize = parserNamespace.batch_size\n",
    "        \n",
    "\n",
    "    def loadModel(self, genGonf):\n",
    "        modelBucket = genGonf.stClient.get_bucket(genGonf.modelBucketName)\n",
    "        \n",
    "        if self.hiddenLayers > -1:\n",
    "            self.modelName = 'Model_'+str(self.hiddenLayers)+'_Layers_'+str(self.tierLevel)+'_Tier_'+str(self.vocabularySize)\n",
    "        else:\n",
    "            self.modelName = 'Model_roberta-base_'+str(self.tierLevel)+'_Tier_'+str(self.vocabularySize)\n",
    "        \n",
    "        for file in modelBucket.list_blobs(prefix=str(self.modelName)):\n",
    "            if not os.path.exists(os.path.join(genGonf.tempDownloadFolder,str(self.modelName))):\n",
    "                os.makedirs(os.path.join(genGonf.tempDownloadFolder,str(self.modelName)))\n",
    "            file.download_to_filename(os.path.join(genGonf.tempDownloadFolder,file.name))\n",
    "\n",
    "        self.robertaModel = RobertaForSequenceClassification.from_pretrained(os.path.join(genGonf.tempDownloadFolder,str(self.modelName)))\n",
    "        \n",
    "        \n",
    "class generalConfig:\n",
    "    def __init__(self):\n",
    "        self.logLevel = logging.INFO\n",
    "        self.vocabularySize: int = 50265\n",
    "        self.projectID = 'mwrite-a835'\n",
    "        self.reRun = 0\n",
    "        \n",
    "        self.predResultsBucketName: str = 'mpr-research-prediction-results'\n",
    "        \n",
    "        self.tokenizerBucketName: str = 'mpr-research-tokenizers'\n",
    "        self.modelBucketName: str = 'mpr-research-models'\n",
    "        \n",
    "        self.dataTableID: str = 'mwrite-a835.mpr_research_uploaded_dataset.course-upload-data'\n",
    "        self.timestampTableID: str = 'mwrite-a835.mpr_research_uploaded_dataset.course-upload-timestamp'\n",
    "        self.predictTableID: str = 'mwrite-a835.mpr_research_predicted_dataset.predicted-data'\n",
    "        \n",
    "        self.tempDownloadFolder: str = './tmp'\n",
    "        if not os.path.exists(self.tempDownloadFolder):\n",
    "            os.makedirs(self.tempDownloadFolder)\n",
    "\n",
    "        self.labelTierDict = {1:['Verification/Summary', 'Praise', 'Problem/Solution'],\n",
    "                              2:['WritingOrFormatting Issues', 'Missing Content', 'Incorrect Content']}\n",
    "        self.binaryDict = {0:'No', 1:'Yes'}\n",
    "\n",
    "        self.coreColumns = ['AuthorID','ReviewerID','Criterion','Course','Comment']\n",
    "        self.tierColumsDict = {1:['CommentCode'], 2:['WritingFormatting', 'MissingContent', 'Incorrect']}\n",
    "\n",
    "        self.stClient = storage.Client(project=self.projectID)\n",
    "        self.bqClient = bigquery.Client(project=self.projectID)\n",
    "        \n",
    "        self.robertaTokenizer = None\n",
    " \n",
    "    \n",
    "    def setUpFromArgs(self):\n",
    "        parserNamespace = setUpParser()\n",
    "        self.logLevel = parserNamespace.logging_level\n",
    "        self.vocabularySize = parserNamespace.vocabulary_size\n",
    "        self.projectID = parserNamespace.projectid\n",
    "        self.reRun = parserNamespace.rerun\n",
    "        \n",
    "        self.predResultsBucketName = parserNamespace.prediction_bucket\n",
    "        \n",
    "        self.tokenizerBucketName = parserNamespace.tokenizer_bucket\n",
    "        self.modelBucketName = parserNamespace.model_bucket\n",
    "        \n",
    "        self.dataTableID = parserNamespace.data_table\n",
    "        self.timestampTableID = parserNamespace.timestamp_table\n",
    "        self.predictTableID = parserNamespace.predict_table\n",
    "        \n",
    "            \n",
    "    def loadTokenizer(self):\n",
    "        tokenizerBucket = self.stClient.get_bucket(self.tokenizerBucketName)\n",
    "\n",
    "        for file in tokenizerBucket.list_blobs(prefix=str(self.vocabularySize)):\n",
    "            if not os.path.exists(os.path.join(self.tempDownloadFolder,str(self.vocabularySize))):\n",
    "                os.makedirs(os.path.join(self.tempDownloadFolder,str(self.vocabularySize)))\n",
    "            if not os.path.exists(os.path.join(self.tempDownloadFolder,file.name)):\n",
    "                file.download_to_filename(os.path.join(self.tempDownloadFolder,file.name))\n",
    "\n",
    "        self.robertaTokenizer = RobertaTokenizer.from_pretrained(os.path.join(self.tempDownloadFolder,str(self.vocabularySize)), do_lower_case=True)\n",
    "            \n",
    "    \n",
    "class peerDataset(Dataset):\n",
    "    def __init__(self, df, baseConf):\n",
    "        self.config = baseConf\n",
    "        self.comments = df['Comment'].values \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.tokenizedData = sentenceTokenizer(self.comments[idx], self.config .robertaTokenizer)\n",
    "        return self.tokenizedData\n",
    "    \n",
    "    \n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def setUpParser():\n",
    "    parser = argparse.ArgumentParser(description='Take in command line arguments.')\n",
    "    parser.add_argument(\n",
    "        '--projectid',\n",
    "        help='Enter Project ID. Defaults to \"mwrite-a835\".',\n",
    "        default='mwrite-a835',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--rerun',\n",
    "        help='Set to 1 if to run on all courses, regardless of prediction status, else set to 0. Defaults to 0.',\n",
    "        default=0,\n",
    "        type=int)\n",
    "    parser.add_argument(\n",
    "        '--vocabulary-size',\n",
    "        help='Vocabulary size for Roberta Tokenizer and Models. Defaults to 50265.',\n",
    "        choices=[50265,30522],\n",
    "        default=50265,\n",
    "        type=int)\n",
    "    parser.add_argument(\n",
    "        '--hidden-layers',\n",
    "        help='Number of hidden layers to use if building a model from Roverta Config is used. Set to -1 to use roberta-base instead. Defaults to -1.',\n",
    "        default=-1,\n",
    "        type=int)\n",
    "    parser.add_argument(\n",
    "        '--batch-size',\n",
    "        help='Batch size for data fed to the model. Defaults to 16. Warning, higher batch sizes need higher memory requirements, make sure your job is configured appropiately.',\n",
    "        default=16,\n",
    "        type=int)\n",
    "    parser.add_argument(\n",
    "        '--tokenizer-bucket',\n",
    "        help='GCP bucket where tokenizer files are stored. Defaults to \"mpr-research-tokenizers\".',\n",
    "        default='mpr-research-tokenizers',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--model-bucket',\n",
    "        help='GCP bucket where model files are uploaded after training. Defaults to \"mpr-research-data\".',\n",
    "        default='mpr-research-models',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--data-predict-bucket',\n",
    "        help='GCP bucket where course data are saved as TSV files. Defaults to \"mpr-research-data-uploads\".',\n",
    "        default='mpr-research-data-uploads',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--prediction-bucket',\n",
    "        help='GCP bucket where course data predictions are saved as CSV files. Defaults to \"mpr-research-prediction-results\".',\n",
    "        default='mpr-research-prediction-results',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--data-table',\n",
    "        help='BigQuery table where course data is stored. Defaults to \"mwrite-a835.mpr_research_uploaded_dataset.course-upload-data\".',\n",
    "        default='mwrite-a835.mpr_research_uploaded_dataset.course-upload-data',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--timestamp-table',\n",
    "        help='BigQuery table where course upload timestamp data is stored. Defaults to \"mwrite-a835.mpr_research_uploaded_dataset.course-upload-timestamp\".',\n",
    "        default='mwrite-a835.mpr_research_uploaded_dataset.course-upload-timestamp',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--predict-table',\n",
    "        help='BigQuery table where predicted data is uploaded. Defaults to \"mwrite-a835.mpr_research_predicted_dataset.predicted-data\".',\n",
    "        default='mwrite-a835.mpr_research_predicted_dataset.predicted-data',\n",
    "        type=str)\n",
    "    parser.add_argument(\n",
    "        '--logging-level',\n",
    "        help='Set default Logging Level. Defaults to INFO.',\n",
    "        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'FATAL'],\n",
    "        default='INFO',\n",
    "        type=str)\n",
    "    \n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def sentenceTokenizer(sentence, tokenizer):\n",
    "    tokenizedSentence = tokenizer(sentence, add_special_tokens = True, \n",
    "                                  max_length= 512, truncation='longest_first', padding='max_length', \n",
    "                                  return_attention_mask=True, return_tensors='pt')\n",
    "    tokenizedSentence = {key:tokenizedSentence[key][0] for key in tokenizedSentence}\n",
    "    return tokenizedSentence\n",
    "\n",
    "\n",
    "def trainerBuilder(genConf, config):\n",
    "    trainingArgs = TrainingArguments(\n",
    "                            output_dir=os.path.join(genConf.tempDownloadFolder,'trainerTier'+str(config.tierLevel)+'Logs'),\n",
    "                            per_device_eval_batch_size=config.batchSize,\n",
    "                            )\n",
    "    trainer = Trainer(\n",
    "                    model=config.robertaModel,\n",
    "                    args=trainingArgs,\n",
    "                    )\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "\n",
    "def makePredictions(row, baseConfig, trainerDict):\n",
    "    \n",
    "    dataRetrievalQuery = f\"SELECT * FROM `{baseConfig.dataTableID}` WHERE CourseID = {row['CourseID']}\"\n",
    "    dataDF = baseConfig.bqClient.query(dataRetrievalQuery).result().to_dataframe()\n",
    "\n",
    "    dfTier1Slice = dataDF[baseConfig.coreColumns].dropna()\n",
    "    dataLoaderTier1 = peerDataset(dfTier1Slice, baseConfig)\n",
    "    predsDictTier1 = trainerDict[1].predict(dataLoaderTier1)\n",
    "    predListTier1 = np.argmax(predsDictTier1.predictions, axis=-1)\n",
    "    dfTier1Slice['Tier 1 Predictions'] = [baseConfig.labelTierDict[1][predValue] for predValue in predListTier1]\n",
    "\n",
    "    dfTier2Slice = dfTier1Slice[dfTier1Slice['Tier 1 Predictions'] == 'Problem/Solution'].copy()\n",
    "    dataLoaderTier2 = peerDataset(dfTier2Slice, baseConfig)\n",
    "    predsDictTier2 = trainerDict[2].predict(dataLoaderTier2)\n",
    "    predListTier2 = np.where(predsDictTier2.predictions > 0, 1, 0)\n",
    "    for index, col in enumerate(baseConfig.labelTierDict[2]):\n",
    "        dfTier2Slice[col] = [baseConfig.binaryDict[predValue] for predValue in predListTier2[:,index]]\n",
    "    finalDF = dfTier1Slice.join(dfTier2Slice[baseConfig.labelTierDict[2]])\n",
    "    finalDF.columns = finalDF.columns.str.replace(' ', '_')\n",
    "    \n",
    "    return finalDF\n",
    "\n",
    "def runOnBQTable(baseConfig, trainerDict, forcePredict=True):\n",
    "    \n",
    "    timestampQuery = f\"SELECT * FROM `{baseConfig.timestampTableID}`\"\n",
    "    timestampDF = baseConfig.bqClient.query(timestampQuery).result().to_dataframe()\n",
    "    \n",
    "    for _, row in timestampDF.iterrows():\n",
    "        if not row['isPredicted'] or forcePredict:\n",
    "            logging.info(f\"Processing data for {row['CourseID']} - {row['Course']}.\")\n",
    "            finalDF = makePredictions(row, baseConfig, trainerDict)\n",
    "            uploadSuccess = uploadPredictionToGCPTable(row, finalDF, baseConfig)\n",
    "        else:\n",
    "            logging.info(f\"{row['CourseID']} - {row['Course']} already predicted on.\")\n",
    "    \n",
    "\n",
    "def uploadPredictionToGCPTable(row, finalDF, baseConfig):\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Deleting past {row['Course']} course data and updating.\")\n",
    "        deleteQuery = f\"DELETE FROM `{baseConfig.predictTableID}` WHERE Course = '{row['Course']}'\"\n",
    "        deleteJob = baseConfig.bqClient.query(deleteQuery)\n",
    "\n",
    "        logging.info(f\"Saving {row['Course']} to GCP: {baseConfig.predictTableID}\")\n",
    "        uploadJobConfig = bigquery.LoadJobConfig()\n",
    "        uploadJob = baseConfig.bqClient.load_table_from_dataframe(\n",
    "                                        finalDF, \n",
    "                                        baseConfig.predictTableID, \n",
    "                                        job_config=uploadJobConfig\n",
    "                                       )\n",
    "        predictionCompleteQuery = f\"UPDATE `{baseConfig.timestampTableID}` SET isPredicted = true WHERE CourseID = {row['CourseID']}\"\n",
    "        timestampUpdateJob = baseConfig.bqClient.query(predictionCompleteQuery)\n",
    "        return True\n",
    "\n",
    "    except GCPExceptions.NotFound as e:\n",
    "        logging.error(f'Error Message: {e}')\n",
    "        logging.error(\n",
    "            f\"Failed to upload Course Data for {row['Course']} to GCP table.\")\n",
    "        return False\n",
    "    \n",
    "\n",
    "# For debugging only\n",
    "def wipeAllBQData(basicConfig):\n",
    "    basicConfig.bqClient.query(f'DELETE FROM `{basicConfig.targetTableID}` WHERE true')\n",
    "    basicConfig.bqClient.query(f'DELETE FROM `{basicConfig.timestampTableID}` WHERE true')\n",
    "    logging.info('Wiped data from all tables.')\n",
    "\n",
    "# For debugging only\n",
    "def wipeAllPredictData(basicConfig):\n",
    "    basicConfig.bqClient.query(f'DELETE FROM `{basicConfig.predictTableID}` WHERE true')\n",
    "    logging.info('Wiped data from prediction table.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84425c4e-2b66-49e4-95b9-2727dc4efac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./tmp/Model_roberta-base_2_Tier_50265/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"multi_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file ./tmp/Model_roberta-base_2_Tier_50265/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./tmp/Model_roberta-base_2_Tier_50265.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 498928 - CHEM 216 100 WN 2022 already predicted on.\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 516081 - STATS 250 ROMERO WN 22 already predicted on.\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 496007 - CLIMATE 102 001 WN 2022 already predicted on.\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 508768 - ECON 101 300 WN 2022 already predicted on.\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 495677 - Math 216 WN 2022 already predicted on.\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 496915 - MOVESCI 110 WN 2022 already predicted on.\n",
      "2022-07-05T14:08:13+0000 INFO [3376117280.py:268] - 506914 - MATSCIE 250 100 WN 2022 already predicted on.\n"
     ]
    }
   ],
   "source": [
    "basicConfig = generalConfig()\n",
    "#basicConfig.setUpFromArgs()\n",
    "basicConfig.loadTokenizer()\n",
    "\n",
    "configByTierDict = {1:trainerConfig(), 2:trainerConfig()}\n",
    "trainerByTierDict = {1:None, 2:None}\n",
    "\n",
    "for tierLevel in configByTierDict:\n",
    "    #configByTierDict[tierLevel].setUpFromArgs()\n",
    "    configByTierDict[tierLevel].tierLevel = tierLevel\n",
    "    configByTierDict[tierLevel].loadModel(basicConfig)\n",
    "\n",
    "    trainerByTierDict[tierLevel] = trainerBuilder(basicConfig, configByTierDict[tierLevel])\n",
    "\n",
    "runOnBQTable(basicConfig, trainerByTierDict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fe4dbb-2987-42a5-9106-c51c3b0d4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import torch\n",
    "\n",
    "class TransformersClassifierHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    The handler takes an input string and returns the classification text \n",
    "    based on the serialized transformers checkpoint.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(TransformersClassifierHandler, self).__init__()\n",
    "        \n",
    "        self.basicConfig = generalConfig()\n",
    "        #basicConfig.setUpFromArgs()\n",
    "        self.basicConfig.loadTokenizer()\n",
    "        self.configByTierDict = {1:trainerConfig(), 2:trainerConfig()}\n",
    "        for tierLevel in self.configByTierDict:\n",
    "            #configByTierDict[tierLevel].setUpFromArgs()\n",
    "            self.configByTierDict[tierLevel].tierLevel = tierLevel\n",
    "            self.configByTierDict[tierLevel].loadModel(self.basicConfig)\n",
    "\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        \"\"\" Loads the model.pt file and initialized the model object.\n",
    "        Instantiates Tokenizer for preprocessor to use\n",
    "        Loads labels to name mapping file for post-processing inference response\n",
    "        \"\"\"\n",
    "        self.manifest = ctx.manifest\n",
    "        properties = ctx.system_properties\n",
    "        self.device = torch.device(\"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\")\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\" Preprocessing input request by tokenizing\n",
    "            Extend with your own preprocessing steps as needed\n",
    "        \"\"\"\n",
    "        # text = data[0].get(\"data\")\n",
    "        # if text is None:\n",
    "        #     text = data[0].get(\"body\")\n",
    "        # sentences = text.decode('utf-8')\n",
    "        # logger.info(\"Received text: '%s'\", sentences)\n",
    "        \n",
    "        sentences = data\n",
    "\n",
    "        # Tokenize the texts\n",
    "        tokenizer_args = ((sentences,))\n",
    "        tokenizedSentences = self.basicConfig.robertaTokenizer(*tokenizer_args, add_special_tokens = True, \n",
    "                                  max_length= 512, truncation='longest_first', padding='max_length', \n",
    "                                  return_attention_mask=True, return_tensors='pt')\n",
    "        return tokenizedSentences\n",
    "    \n",
    "    def inference(self, inputs):\n",
    "        \"\"\" Predict the class of a text using a trained transformer model.\n",
    "        \"\"\"\n",
    "        predictionsDict = {}\n",
    "        with torch.no_grad():\n",
    "            logits = self.configByTierDict[1].robertaModel(**inputs).logits\n",
    "        predicted_class_id = logits.argmax().item()\n",
    "        predictionsDict['Tier 1 Predictions'] = self.basicConfig.labelTierDict[1][predicted_class_id]\n",
    "\n",
    "        if predictionsDict['Tier 1 Predictions'] == 'Problem/Solution':\n",
    "            with torch.no_grad():\n",
    "                logits = self.configByTierDict[2].robertaModel(**inputs).logits\n",
    "            predicted_class_id = np.where(logits > 0, 1, 0)[0]\n",
    "            for index, col in enumerate(self.basicConfig.labelTierDict[2]):\n",
    "                predictionsDict[col] = self.basicConfig.binaryDict[predicted_class_id[index]] \n",
    "        else:\n",
    "            for index, col in enumerate(self.basicConfig.labelTierDict[2]):\n",
    "                predictionsDict[col] = None\n",
    "\n",
    "        return [predictionsDict]\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        return inference_output\n",
    "    \n",
    "    \n",
    "# baseHandler = TransformersClassifierHandler()\n",
    "# tokenizedData = baseHandler.preprocess('This is a test sentence and I think I love it.')\n",
    "# baseHandler.inference(tokenizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5d32a-e142-49c4-9a76-a9253588f9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
